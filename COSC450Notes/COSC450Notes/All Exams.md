
## Mini Test One

### Question One 

a. What are the five layers of the operating system that we are going to discuss during the semester? 
	1. Processes
	2. File systems
	3. Memory
	4. I/O
	5. Deadlock 

b. What is the Von Neumann bottleneck? 
	**MY ANSWER**: It is caused by an issue with throughput - the process completes calculations fastre than data can transfer between it and memory. 
	**DR. PARK'S SOLUTION**: since fetch cycle is much slower than the execute cycle.

c. The CPU is composed with several components: ALU, control units, registers. The program counter is one of the registers in the CPU. What is the role of the program counter? 
	**MY ANSWER**: The program counter contains the location of the next valid instruction in memory (virtual address).
	**DR. PARK'S SOLUTION**: save the virtual address of the next instruction

d. What is the batch system? 
	**MY ANSWER**: in the second generation of computing, the batch system was when they had 2 IBM systems for computing: one for processing (1401) and  for writing to magnetic tape and one (7094) for completing computations.
	**DR PARK'S SOLUTION**: similar jobs are collected and saved in a magnetic tape and implement one by one sequentially

e. What is multiprogramming? 
	**MY ANSWER**: When multiple programs are loaded into RAM and wait in the ready queue. When the CPU is free, the short term scheduler chooses the next program to run. 
	**DR PARK'S SOLUTION**: several jobs are loaded into RAM and the OS supports pseudo-parallelism

f. Why does the OS not need to protect between threads in a process?
	**DR PARK'S SOLUTION**: Because threads are using the same address space.

g. What is the reaction of operating systems when the CPU is interrupted by any I/O devices? 
	**MY ANSWER**: it immediately jumps to where the service routine is in low memory in order to complete the interrupt before returning to its location
	**DR PARK'S SOLUTION**: OS stops what it is currently doing and immediately transwers execution to a fixed location where the service routine for the interrupt is located

h. What is the role of the interrupt request line? 
	**MY ANSWER**: it is a hardware wire in the CPU that allows device controllers and hardware faults to directly inform the CPU of an interrupt
	**DR PARK'S SOLUTION**: the CPU detects the interrupt from the interrupt request line and it reads the interrupt number and jumps to the interrupt handler routine. 

i. The form of interrupt-drive I/O is fine for moving small amounts of data but can produce high overhead when used for bulk data movement. What is the solution to reduce the overhead? 
	**MY ANSWER**: direct memory access (DMA)
	**DR PARK'S SOLUTION**: DMA

j. Why are deadlocks between processes are necessary, if the OS does not take care of deadlock? 
	**MY ANSWER**: because there will always be fewer resources than processes occuring. 
	**DR PARK'S SOLUTION**: since there are a limited number of resources which much be shared between processes. 

k. Microkernel is one of the OS structures. Briefly explain the basic idea of the microkernel. 
	**MY ANSWER**: there are many modules running in the OS, but only one is running in kernel modes while the others are in user mode. 
	**DR PARK'S SOLUTION**: to achieve high reliability, the OS is broken into small well-defined modules. Only one module is run in kernel mode and the rest are run in user mode. 

l. What are the three main functions for the OS to control each of the I/O devices? 
	Issue commands, catch interrupts, handle errors 

m. What are the four necessary conditions for a deadlock? 
	Mutual exclusion, hold and wait, circular wait, no preemption. 

n. Adding an additional CPU to a muliprocessor system will increase computing power. Why does adding many CPU cause performance degredation? 
	**MY ANSWER**: because the amount of overhead that is generated by adding additional CPUs eventually outweighs the speed of multiple CPUs. 
	**DR PARK'S SOLUTION**: due to heavy data transfer, bus becomes a bottleneck 

o. What is the potential draw back in non-uniform memory access in multiprocessor systems? 
	**MY ANSWER**: addressing remote memory is remarkably slower compared to accessing the local cache memory
	**DR PARK'S SOLUTION**: increased latency when a CPU must access remote memory across the system interconnect, creating a possible performance penalty. 

p. Briefly explain asymmetric and symmetric clustering. 
	**MY ANSWER**: *asymmetric clustering* is when one machine is on hot standby, monitoring all othere machines. If one fails, it takes the failed machine's place. *Symmetric clustering* is when multiple machines are running as one node in a collection of nodes.
	**DR PARK'S SOLUTION**: *asymmetric clustering* is when one machine is in hot standby mode. The hot standby host machine just monitors the active server. If that server fails, the hot standby host becomes the active server. *Symmetric clustering* is when two or more hosts are running applications and monitoring each other.

q. What are the three major activites of the OS with regards to memory?
	**MY ANSWER**: knowing what processes/parts of processes are in memory, deallocation and allocation, moving data and processes in and out of memory
	**DR PARK'S SOLUTION**: keep track of which parts of memory are currently being used by which process, allocate and deallocate memory space as needed for each process, decide which processes are to be loaded into memory when memory space becomes available

r. An OS is responsible for activities for secondary storage management. List five of them.
	Unmounting and mounting, partitioning, free space mangement, storage allocation, protection, disk scheduling

s. What is the motivation of virtual memory?
	**MY ANSWER**: allows multiple different items to be mapped to absolute memory addresses and for the CPU to hold more memory at any given time
	**DR PARK'S SOLUTION**: limited size of memory, big process sizes

t. What are three components for an I/O device? 
	**MY ANSWER**: mechanical (the device), electrical (device controller), software (device driver)
	**DR PARK'S SOLUTION**: ""

u. What is spooling? 
	**MY ANSWER**: a form of promoting multiprogramming by loading jobs into a temporary file to be read/chosen by a scheduler (main example is printers)
	**DR PARK'S SOLUTION**: jobs for processes (I/O devices) are saved in a file and executed one by one

v. An OS keeps a process table for each process. Name three contents of a process table? 
	**MY ANSWER**: address of process, pid, parent process
	**DR PARK'S SOLUTION**: process status, snapshot of CPU, scheduling information, memory management information, I/O status information

w. Briefly discuss about the instruction cycle.
	**MY ANSWER**: fetch (instructions from memory using the PC), decode (decode in IR), execute (excecute in the CPU)
	**DR PARK'S SOLUTION**: fetching an instruction to the CPU, decode and then execute the instruction 

x. What are the three main functions of the OS for supporting multiprogramming? 
	**DR PARK'S SOLUTION**: protection between jobs, job scheduling, virtual memory 

y. Why can CPU performance can be improved by using pipelining design? 
	**MY ANSWER**: because it allows for more tasks to complete as different tasks take different amounts of time and have different priorities.
	**DR PARK'S SOLUTION**: since the instruction cycle is three steps: fetch, decode, execute 

z. What is timesharing?
	**MY ANSWER**: multiple terminals sharing time on the CPU
	**DR PARK'S SOLUTION**: multiple monitors are connected to a host computer and each user is in a shared system.

## Mini Test Two 

### Question One

Consider the following set of processes (which are 100% CPU-bounded): 

| Process | CPU-time | Priorities | Arrival time | 
| ------- | -------- | ---------- | ------------ |
| $P_1$ | 11 | 2 | 0 |
| $P_2$ | 7 | 3 | 3 |
| $P_3$ | 4 | 5 | 5 |
| $P_4$ | 7 | 4 | 7 |
| $P_5$ | 3 | 1 | 8 |

Calculate the average waiting time and the average turnaround time with *Preemptive Shortest Remaining Time First* amd *Preemptive Priority Queue* process scheduling algorithms. Ignore process switcing overhead. Higher number has higher priorties. 

1. Shortest remaining time first (preemptive)

|  $P_1$  |  $P_2$ |  $P_3$  | $P_3$ |  $P_5$  |   $P_5$   |   $P_2$   |    $P_4$    |     $P_1$    | 
| --- | -- | --- | - | --- | ----- | ------- | -------- | 
| --3-  |  -2-  |  --3-  | 1 |  --3-  | ---5-- | ----7--- | ----8---- | 


**Average waiting time**: $((24-3) + (12-5) + 0 + (17-7) + 1)/ 5 = 7.8$
**Average turnaround time**: $((32-0) + (17-3) + (9-5) + (24-7) + (12-8))/5 = 14.2$

2. Preemptive priority queue 

|  $P_1$  |  $P_2$ |  $P_3$  | $P_4$ |  $P_2$  |   $P_1$   |   $P_5$   |  
| --- | -- | --- | - | --- | ----- | --- |
| --3-  |  -2-  |  --4--  | ----7--- |  ---5--  | ----8---- | --3- |  

**Average waiting time**: $((21-3) + (16-5) + 0 + (9-7) + (29-8))/5 = 10.4$
**Average turnaround time**: $((29-0) + (21-3) + (9-5) + (16-7) + (32-8))/5 = 16.8$

### Question Two 

Miss Wonder presents a solution for the mutual exclusion with busy waiting.  Variable **IN** can be true or false. If **IN = True**, a process is in busy waiting outside the critical section. If **IN = False,**  a process can set **IN = True** and go into the critical section. Once a process finishes its job in the critical section, set **IN = False** and let other processes into the critical section. 

```
repeat 
	while IN != False do
		; (no operation)
	IN = true 
		critical section
	IN = False
		remainder section
until False
```

Does her method work for mutual exclusion? Discuss Miss Wonder's solution. If her method guarantees mutual exclusion, explain how. If her method does not work, write a scenario that leeads to the situation which violates thhe mutual exclusion. 

This scenario does not work for mutual exclusion. 

IN = False at the beginning. There are two processes, $P_0$ and $P_1$. 
- $P_0$ is scheduled and tries to go into the critical section.
- $P_0$ reads IN = False and then times out. $P_0$'s status changes from running to ready state.
- $P_1$ is scheduled and tries to enter the critical section. 
- $P_1$ reads IN = False and sets IN = True and goes into the critical section.
- Sometime later in the critical section, $P_1$ times out. $P_1$'s status changes from running to ready. 
- $P_0$ is rescheduled and tries to enter the critical section. $P_0$ already read IN = False, so $P_0$ sets IN = True again and enters the critical section.
- Now both processes are in the critical section and violates mutual exclusion.

### Question Three

A solution for the race condition should have 4 necessary conditions. List them.

1. No two processes may be simultaneously inside their critical region (mutual exclusion)
2. No processes running outside its critical region may block other processes
3. No processes should have to wait forever to enter the critical region
4. No assumptions may be made about speeds or the number of CPUs

### Question Four 

Mr. Computere tries to solve the race condition problem in the producer-consumer problem by using semaphores. Does his method avoid the race conditions? If it does work to avoid the race condition, explain how. If it does not work, write a scenario that leads to the situation that violates the race condition.

``` 
#define N 100
typedef int semaphore;
semaphore mutex = 1;
semaphore empty = N;
semaphore full = 0 

void producer() { 
	
	int item;
	while (true) { 
	
		item = produce_item();
		down (&mutex);
		down (&empty);
		insert_item(item);
		up (&mutex);
		up (&full);
	
	}

}

void consumer() { 

	int item;
	while(true) { 
	
		down (&full);
		down (&mutex);
		item = remove_item();
		up (&mutex);
		up (&empty);
		consume_item(item); 
	
	}

}
```

This solution does not avoid the race condition. Let mutex = 1, empty = 0, and full = N. The short term scheduler chooses the producer. The producer downs the mutex, so mutex = 0. It then tries to down the empty, but since it is already 0, the producer gets sent to the semaphore wait queue. The short term scheduler then chooses the consumer. The consumer downs the full, then goes to down the mutex, which is already 0. The consumer also gets sent to the semaphore wait queue. Thus, there is a deadlock. 

### Question Five

Peterson's solution solves the race condition, but has the defect of requring busy waiting. Not only does this approach waste CPU time, but also it can have an unexpected problem called the *priority inversion problem*. What is the priority inversion problem with busy waiting? 

Assume there are two processes, $P_H$ and $P_L$ and $P_H \gt P_L$.  The priority inversion problem is when a lower priority processes is unable to release the critical section because the CPU scheduling dictates that a higher priority process always gest CPU time when it is in the ready state. 

$P_L$ is in the critical section and $P_H$ is in the block state. $P_H$ moves to the ready state and the scheduler preemptively chooses it. $P_L$ is moved to the ready state, but cannot give up the critical section because it cannot get CPU time to release it. Thus, $P_H$ is stuck busy waiting for the critical section. 

### Question Six

Why is the many-to-one multi-threading model not have benefits on multi-processor systems? 

The many to one model does not allow a system to fully take advantage of parallelism. If one thread makes a blocking call, all user threads mapped to that kernel thread are also blocked. 

### Question Seven

Briefly explain what are the main differences between user-level threads and kernel-level threads.

User level threads exists in the user space and don't require a context switch in order to switch threads; they are also relatively fast and easy to create. Kernel threads exist in the kernel space and are generally slower to create and use; they also require a context switch in oorder to change threads and allow parallelism. 

## Mini Test Three

### Question One 

$128 MB$ memory is allocated in units of $2KB$. For linked list, assume that memory currently consists of an alternating sequence of segments and holes, each $64KB$. Assume that each node in the linked list neesd a $32 bit$ memory addresses, a $16 bit$ length, and a $16 bit$ next node field. How many bytes of storage are needed for each method? 

a. Bitmap = size of memory / size of block 

$128 MB / 2KB = 2^{27} / 2^{11} = 2^{16}$ bytes of storage 

b. Linked List

$128MB / 64KB = 2^{27} / 2^6 = 2^{11}$ nodes 
size of node = 32 bits + 16 bits + 16 bits = 64 bits = 8 bytes
$2^{11} * 2^3$ = $2^{14}$ bytes of storage

### Question Two 

Consider a swapping system in which memory consists of the following hole size in memory order: 21KB, 20KB, 4KB, 18KB, 15KB, 14KB, 25KB, 23KB, 35KB. 

What hole is taken for a successive segment request of 9KB, 10KB, 15KB, and 18KB? 

- First Fit: 21 -> 20 -> 18 -> 25
- Best Fit: 14 -> 15 -> 18 -> 20 
- Worst Fit: 35 -> 25 -> 23 -> 21
- Next Fit: 21 -> 20 -> 18 -> 25

### Question Four

A computer system generates a 32 bit virtual address for a process. This system has an 8GB RAM and a 4KB page size. 

a. If each entry in the page table needs 64 bits per entry, calculate the possible size of the page table by bytes. 

$2^{32} = 4GB$ virtual page size 
$4GB/4KB = 2^{32}/2^{12} = 2^{20}$ pages 
$8GB/4KB = 2^{33}/2^{12} = 2^{21}$ page frames

$8 * 2^{20} = 2^3 * 2^{20} = 2^{23}$ bytes 

b. Page frame number information for each page must be saved in the page table. How many bits does it need to save page frame number information? 

Because there are $2^{21}$ page frames, 21 bits are required to save the page frame information. 

### Question FIve

A operating system might support three types of schedulers. Briefly discuss them. 

- Short term scheduler: selects a process from the ready queue and allocates the CPU
- Long term scheduler: selects a process from the pool of jobs and loads it into memory for execution
- Memory scheduler: scheduler which process is in memory and in disk for supporting a certain degree of multiprogramming

### Question Six

Why does maintaining page tables in memory result in slower memory access time? 

To access an instruction located a virtual address I, the OS needs two memory access times: access a memory to get page frame numbers from the page table in memory and to calculate the physical address by combining page frame number and offset. 

### Question Seven

The TLB (translation look-aside buffer) is the common solution in modern computer systems. Explain briefly how it works for improving memory access times. 

TLB maintains parts of page information which are used frequently. Usually the register is much faster than RAM access, so you can check the TLB before checking the page frame number information in the page table. 

## Mini Test Four

### Question One

Briefly discuss physical and logical dumps. 

- Physical dump: start at block 0 of the disk, writes all the disk blocks onto the output tape or disk in order, stop when it has copied the last one.
- Logical dump: starts at one or more specified directories and recursively dumps all files and directories found there that have changed since some given base date.
	- Phase 1: begins at starting directory and examines all the entries in it; for each modified file, its i-node is marked in the bitmap. Each directory is also marked and recursively inspected. 
	- Phase 2: unmarking any directories that have no modified files or directories in or under them 
	- Phase 3: all marked directories are dumped
	- Phase 4: all marked files are dumped 

### Question Two 

With an i-node that contains 8 direct addresses which are 64 bits each with a block size is 4KB. If a file uses i-node and one extra bock to save information, what would be the maximum file size? 

number of addresses per block = $8*4KB / 64 bits$ = $2^{15} / 64 = 512$ addresses
size of addresses = $512 * 4KB$ = 2048KB
size of direct addresses = $8*4KB$ = 32KB
max file size =  2080KB 

### Question Three

Let's say a block size is 4KB with a 32 bit disk block number in the file system. 

a. How many maximum blocks are needed to keep track of a 128 GB disk with linked list? 

number of addresses per block = $8*4KB / 32$ = $2^{15} / 32$ -1 = 1023 addresses
number of files per disk = $2^{37}/2^{12} = 2^{25}$ files
number of blocks = $2^{25}/1023$ = 32801 blocks

b. How many blocks are needed for keeping track of a 128 GB disk with bitmap? 

number of blocks = $2^{37}/2^{12} = 2^{25}$ blocks
size of bitmap = $2^{25}/2^3 = 2^{22}$ bytes 
number of blocks needed for bitmap = $2^{22}/2^{12} = 2^{10} = 1024$ blocks 

c. What is the maximum disk size supported by the file system? 

$2^{32} * 4KB = 2^{32} * 2^{12} = 2^{44}  =$ 16 TB 

### Question Four

User B and C are sharing a file by saving shared file information in each directory. Discuss the problems with this and solutions to it. 

If the file is modified by B or C, it will create issues in the shared file via the race condition or in creation/deletion. The solutions are either to have i-nodes pointing to the files, which you then have to account for more than one user on the file, and maintain the correct i-node. The other solution is to use symbolic links, which owrks since only the real owner has the pointer, though it will cause extra overhead. 

### Question Five

A bitmap is used for managing free disk spaces in a system. The beginning of the free space bitmap looks like tihs after the fisk partition is first formed: 

1000 0000 0000 0000

The system always searches for free blocks starting at the lowest numbered block, so after writing file A, which uses 6 blocks, the bitmap looks like this: 

1111 1110 0000 0000

Show the bitmap after each of the following additional actions: 

- File B is written using 5 blocks: 1111 1111 1111 0000
- File A is deleted: 1000 0001 1111 0000
- File C is written, using 8 blocks: 1111 1111 1111 1100
- File B is deleted: 1000 0011 1111 1100

### Question Six

A system uses bitmap to keep track of free blocks. Let's say that a block size is 2KB. The system uses $2^{12}$ blocks for bitmap. What is the total disk size?

size of bitmap = $2^{11}*2^{12} = 8 * 2^{23} = 2^{26}$ bits = number of blocks 
total disk size = $2^{26} * 2{11} = 2^{37} = 128GB$

